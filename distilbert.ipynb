{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "CHECKPOINT = \"distilbert-base-uncased\"\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load IMDB data (training and eval)\"\"\"\n",
    "    raw_datasets = load_dataset(\"imdb\")\n",
    "    raw_datasets = raw_datasets.shuffle(seed=42)\n",
    "    # remove unnecessary data split\n",
    "    del raw_datasets[\"unsupervised\"]\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], truncation=True)\n",
    "    # We will take a small sample in order to reduce the compute time, this is optional\n",
    "    train_population = random.sample(range(len(raw_datasets[\"train\"])), 100)\n",
    "    test_population = random.sample(range(len(raw_datasets[\"test\"])), 100)\n",
    "    tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "    tokenized_datasets[\"train\"] = tokenized_datasets[\"train\"].select(train_population)\n",
    "    tokenized_datasets[\"test\"] = tokenized_datasets[\"test\"].select(test_population)\n",
    "    tokenized_datasets = tokenized_datasets.remove_columns(\"text\")\n",
    "    tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    trainloader = DataLoader(\n",
    "        tokenized_datasets[\"train\"],\n",
    "        shuffle=True,\n",
    "        batch_size=32,\n",
    "        collate_fn=data_collator,\n",
    "    )\n",
    "    testloader = DataLoader(\n",
    "        tokenized_datasets[\"test\"], batch_size=32, collate_fn=data_collator\n",
    "    )\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/targets/x86_64-linux/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /root/anaconda3/envs/venv/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/venv/lib/python3.11/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /root/anaconda3/envs/venv did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 13:47:15,943] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load as load_metric\n",
    "from transformers import AdamW\n",
    "\n",
    "def train(net, trainloader, epochs):\n",
    "    optimizer = AdamW(net.parameters(), lr=5e-5)\n",
    "    net.train()\n",
    "    for _ in range(epochs):\n",
    "        for batch in trainloader:\n",
    "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "            outputs = net(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "def test(net, testloader):\n",
    "    metric = load_metric(\"accuracy\")\n",
    "    loss = 0\n",
    "    net.eval()\n",
    "    for batch in testloader:\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = net(**batch)\n",
    "        logits = outputs.logits\n",
    "        loss += outputs.loss.item()\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = metric.compute()[\"accuracy\"]\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "net = AutoModelForSequenceClassification.from_pretrained(\n",
    "        CHECKPOINT, num_labels=2\n",
    "    ).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import flwr as fl\n",
    "\n",
    "class IMDBClient(fl.client.NumPyClient):\n",
    "        def get_parameters(self, config):\n",
    "            return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "        def set_parameters(self, parameters):\n",
    "            params_dict = zip(net.state_dict().keys(), parameters)\n",
    "            state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "            net.load_state_dict(state_dict, strict=True)\n",
    "        def fit(self, parameters, config):\n",
    "            self.set_parameters(parameters)\n",
    "            print(\"Training Started...\")\n",
    "            train(net, trainloader, epochs=1)\n",
    "            print(\"Training Finished.\")\n",
    "            return self.get_parameters(config={}), len(trainloader), {}\n",
    "        def evaluate(self, parameters, config):\n",
    "            self.set_parameters(parameters)\n",
    "            loss, accuracy = test(net, testloader)\n",
    "            return float(loss), len(testloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-31 13:47:19,209 | app.py:148 | Starting Flower server, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "INFO flwr 2023-07-31 13:47:19,217 | app.py:168 | Flower ECE: gRPC server running (3 rounds), SSL is disabled\n",
      "INFO flwr 2023-07-31 13:47:19,218 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2023-07-31 13:47:19,218 | server.py:273 | Requesting initial parameters from one random client\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m      8\u001b[0m strategy \u001b[39m=\u001b[39m fl\u001b[39m.\u001b[39mserver\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mFedAvg(\n\u001b[1;32m      9\u001b[0m     fraction_fit\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m,\n\u001b[1;32m     10\u001b[0m     fraction_evaluate\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m,\n\u001b[1;32m     11\u001b[0m     evaluate_metrics_aggregation_fn\u001b[39m=\u001b[39mweighted_average,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[39m# Start server\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m fl\u001b[39m.\u001b[39;49mserver\u001b[39m.\u001b[39;49mstart_server(\n\u001b[1;32m     16\u001b[0m     server_address\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m0.0.0.0:8000\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m     config\u001b[39m=\u001b[39;49mfl\u001b[39m.\u001b[39;49mserver\u001b[39m.\u001b[39;49mServerConfig(num_rounds\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m),\n\u001b[1;32m     18\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m fl\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mstart_numpy_client(\n\u001b[1;32m     22\u001b[0m     server_address\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m127.0.0.1:8000\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     client\u001b[39m=\u001b[39mIMDBClient()\n\u001b[1;32m     24\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/site-packages/flwr/server/app.py:176\u001b[0m, in \u001b[0;36mstart_server\u001b[0;34m(server_address, server, config, strategy, client_manager, grpc_max_message_length, certificates)\u001b[0m\n\u001b[1;32m    168\u001b[0m log(\n\u001b[1;32m    169\u001b[0m     INFO,\n\u001b[1;32m    170\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mFlower ECE: gRPC server running (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m rounds), SSL is \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    171\u001b[0m     initialized_config\u001b[39m.\u001b[39mnum_rounds,\n\u001b[1;32m    172\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39menabled\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m certificates \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdisabled\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    173\u001b[0m )\n\u001b[1;32m    175\u001b[0m \u001b[39m# Start training\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m hist \u001b[39m=\u001b[39m _fl(\n\u001b[1;32m    177\u001b[0m     server\u001b[39m=\u001b[39;49minitialized_server,\n\u001b[1;32m    178\u001b[0m     config\u001b[39m=\u001b[39;49minitialized_config,\n\u001b[1;32m    179\u001b[0m )\n\u001b[1;32m    181\u001b[0m \u001b[39m# Stop the gRPC server\u001b[39;00m\n\u001b[1;32m    182\u001b[0m grpc_server\u001b[39m.\u001b[39mstop(grace\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/site-packages/flwr/server/app.py:217\u001b[0m, in \u001b[0;36m_fl\u001b[0;34m(server, config)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fl\u001b[39m(\n\u001b[1;32m    213\u001b[0m     server: Server,\n\u001b[1;32m    214\u001b[0m     config: ServerConfig,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m History:\n\u001b[1;32m    216\u001b[0m     \u001b[39m# Fit model\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m     hist \u001b[39m=\u001b[39m server\u001b[39m.\u001b[39;49mfit(num_rounds\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnum_rounds, timeout\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mround_timeout)\n\u001b[1;32m    218\u001b[0m     log(INFO, \u001b[39m\"\u001b[39m\u001b[39mapp_fit: losses_distributed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(hist\u001b[39m.\u001b[39mlosses_distributed))\n\u001b[1;32m    219\u001b[0m     log(INFO, \u001b[39m\"\u001b[39m\u001b[39mapp_fit: metrics_distributed_fit \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(hist\u001b[39m.\u001b[39mmetrics_distributed_fit))\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/site-packages/flwr/server/server.py:87\u001b[0m, in \u001b[0;36mServer.fit\u001b[0;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39m# Initialize parameters\u001b[39;00m\n\u001b[1;32m     86\u001b[0m log(INFO, \u001b[39m\"\u001b[39m\u001b[39mInitializing global parameters\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_initial_parameters(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m     88\u001b[0m log(INFO, \u001b[39m\"\u001b[39m\u001b[39mEvaluating initial parameters\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mevaluate(\u001b[39m0\u001b[39m, parameters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/site-packages/flwr/server/server.py:274\u001b[0m, in \u001b[0;36mServer._get_initial_parameters\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39m# Get initial parameters from one of the clients\u001b[39;00m\n\u001b[1;32m    273\u001b[0m log(INFO, \u001b[39m\"\u001b[39m\u001b[39mRequesting initial parameters from one random client\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 274\u001b[0m random_client \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client_manager\u001b[39m.\u001b[39;49msample(\u001b[39m1\u001b[39;49m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    275\u001b[0m ins \u001b[39m=\u001b[39m GetParametersIns(config\u001b[39m=\u001b[39m{})\n\u001b[1;32m    276\u001b[0m get_parameters_res \u001b[39m=\u001b[39m random_client\u001b[39m.\u001b[39mget_parameters(ins\u001b[39m=\u001b[39mins, timeout\u001b[39m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/site-packages/flwr/server/client_manager.py:180\u001b[0m, in \u001b[0;36mSimpleClientManager.sample\u001b[0;34m(self, num_clients, min_num_clients, criterion)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mif\u001b[39;00m min_num_clients \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     min_num_clients \u001b[39m=\u001b[39m num_clients\n\u001b[0;32m--> 180\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait_for(min_num_clients)\n\u001b[1;32m    181\u001b[0m \u001b[39m# Sample clients which meet the criterion\u001b[39;00m\n\u001b[1;32m    182\u001b[0m available_cids \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclients)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/site-packages/flwr/server/client_manager.py:125\u001b[0m, in \u001b[0;36mSimpleClientManager.wait_for\u001b[0;34m(self, num_clients, timeout)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wait until at least `num_clients` are available.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \n\u001b[1;32m    110\u001b[0m \u001b[39mBlocks until the requested number of clients is available or until a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39msuccess : bool\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cv:\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cv\u001b[39m.\u001b[39;49mwait_for(\n\u001b[1;32m    126\u001b[0m         \u001b[39mlambda\u001b[39;49;00m: \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclients) \u001b[39m>\u001b[39;49m\u001b[39m=\u001b[39;49m num_clients, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    127\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait_for\u001b[0;34m(self, predicate, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[39mif\u001b[39;00m waittime \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    354\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(waittime)\n\u001b[1;32m    356\u001b[0m     result \u001b[39m=\u001b[39m predicate()\n\u001b[1;32m    357\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def weighted_average(metrics):\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    losses = [num_examples * m[\"loss\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples), \"loss\": sum(losses) / sum(examples)}\n",
    "\n",
    "# Define strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,\n",
    "    fraction_evaluate=1.0,\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    ")\n",
    "\n",
    "# Start server\n",
    "fl.server.start_server(\n",
    "    server_address=\"0.0.0.0:8000\",\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    "    strategy=strategy,\n",
    ")\n",
    "\n",
    "fl.client.start_numpy_client(\n",
    "    server_address=\"127.0.0.1:8000\",\n",
    "    client=IMDBClient()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
